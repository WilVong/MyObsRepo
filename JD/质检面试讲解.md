
# 1概述
## 1.1背景
我们部门为了做b端的商家新签，需要将排序后的商家联系方式分发到外呼人员中，外呼人员会去询问发单量，价值，时效性等关键信息，并填写表单，质检要做的就是根据录音文本验证表单填写的准确性
## 1.2流程
整体质检流程分为四步：
1.问题抽取：将客服和客户的每句话分类，对应为质检问题的某个类别，或是无类别
2.段落切分：将整个文本切分为若干个文本块，每个质检问题对应一块，切分大体是按一个问题的询问触发到一个问题的回答结束为依据分割的
3.答案抽取：在每个质检问题对应的文本块中找到正确的答案，比如单量是xx，时效性是xx
4.转义：质检要做的事就是验证外呼人员填写表单的正确性，而外呼人员填写的表单中每个问题是固定的枚举值，所以要将抽取出的答案映射为表单中的标准格式，比如价格中：十几块，一百块映射为0-50元，100-200元这种标准表单选项

v0版的方案都是用规则做的，无论是问题抽取还是答案抽取，每个质检类都有多个正则表达式去匹配，但带来的问题是有小部分case是无法被涵盖到的，而且这些case数量多种类杂，不能用有限个正则表达式解决，从而转为模型识别

样本：1.2w个
原始标注：
![[Pasted image 20231203170630.png]]
需要转成模型输入的格式

## 1.3模型
### 1.3.1问题抽取v1
科大讯飞和哈工大合作预训练模型 
[https://github.com/ymcui/Chinese-BERT-wwm](https://github.com/ymcui/Chinese-BERT-wwm)
【ps:wwm：bert预训练MLM时Mask改为分词，从而字的embedding学到词信息】
用其做多标签分类
模型：bert-base参数：12-layer, 768-hidden, 12-heads, 110M 参数
使用bert-large：24-layer, 1024-hidden, 16-heads, 330M参数
样本：multi-hot 
实现Dataset类__getitem__方法
```
return {
	'ids': torch.tensor(ids, dtype=torch.long),
	'mask': torch.tensor(mask, dtype=torch.long),
	'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),
	'targets': torch.tensor(self.targets[index], dtype=torch.float)} 
```
损失：sigmoid+二进制交叉熵（BCE）= nn.BCEWithLogitsLoss
微调训练：batch=32 l_r=2e-5 max_len=120 epoch 4 时间 一小时左右
bert训练显存就十几G
指标：召回率，F1 ps:多分类指标
### 1.3.2段落分割
v0:正则匹配每句话，触发每类问题的询问，分割范围为第一次触发这个问题的句子到下一个触发其他问题的句子
v1:根据每句话的分类结果，每个类别的分割范围为：第一个到最后一个分类为该类别的句子
### 1.3.3答案抽取：MRC
macbert large
