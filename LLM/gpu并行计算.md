#### 1.大模型：模型本身大，数据量大，gpu装不下

#### 2.数据并行:batchsize不能过小，否则梯度随机。过大会导致gpu装不下：单机多卡，同步数据并行，主从思想会有模型隆余
	![[Pasted image 20230831093321.png]]
	eg:96个batch拆分成3个32batch，放a-c三张卡跑，分别计算，三个数据统一更新模型
#### 3.模型并行：
	![[Pasted image 20230831092607.png]]
	会有gpu闲置时间
	优化：
	![[Pasted image 20230831092732.png]]
	多份数据紧接着算，问题:f1-f4用的同一套参数，正常来说f1后就更新w1
#### 4.流水线并行/正交并行：流水线并行模型放多卡，数据放多卡
#### 5.张量并行
	![[Pasted image 20230831093743.png]]
	不涉及多卡，只是矩阵分解，计算优化
#### 6：模型并行：解决模型过大，无法加载的问题
数据并行：解决数据量大，无法加载
两者共性：显存不足
张量并行：为了计算加速优化

#### 7.代码
os.environ['CUDA_VISIBLE_DEVICES']="0,1" 一定要放在最开始；
模型和数据要么都在gpu，要么都在cpu；
数据并行：
	![[Pasted image 20230831095350.png]]
模型并行：
	![[Pasted image 20230831100048.png]]
	![[Pasted image 20230831100153.png]]

#### 8.对于单机多卡：什么都不指定，pytorch默认第一块gpu，huggingface默认模型并行

#### 9.数据位宽
	![[Pasted image 20230831100832.png]]
	![[Pasted image 20230831101052.png]]
	E：指数位，数据大小范围，M:精度位
#### 10.所有的运算，都能转成矩阵运算，所有矩阵运算最终都是加乘运算
	加乘运算占据的算力和内存：
	![[Pasted image 20230831101350.png]]
#### 11.元素运算时并行运算，会非常快（gpu的并行能力）
卷积可以做到计算并行，但做不到数据独立
全连接数据冗余非常大
	![[Pasted image 20230831101622.png]]

#### 12.计算强度：
![[Pasted image 20230831101810.png]]
横轴N，纵轴：计算量C/N



