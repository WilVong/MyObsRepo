# 1.损失函数
## 1.1  torch.nn.BCELoss()（二进制交叉熵)
-  基础的损失函数 BCE （Binary cross entropy）
```
class torch.nn.BCELoss(weight=None, size_average=None, reduce=None, reduction=‘elementwise_mean’)
```
-  pytorch中，表示求一个二分类的交叉熵:
![[Pasted image 20230920015006.png]]
  当参数reduce设置为 True，且参数size_average设置为True时，表示对交叉熵求均值，当size_average设置为Flase时，表示对交叉熵求和。参数weight设置的是 w_n​ ​，其是一个tensor, 且size与批量数一样(不设置时可能都为1)。目标值 y的范围是0-1之间。输入输出的维度都是 ，(N,* ),N是批量数，* 表示目标值维度。
- 使用交叉熵作为损失函数后，反向传播的梯度不在于sigmoid函数的导数有关了。这就从一定程度上避免了梯度消失。而使用MSE和sigmoid将导致梯度消失。

-  分类问题一般又分为：二分类任务、多分类任务和多标签分类任务
二分类任务：输出只有0和1两个类别；——sigmoid
多分类任务：一般指的是输出只有一个标签，类别之间是互斥的关系；——softmax
多标签分类任务：输出的结果是多标签，类别之间可能互斥也可能有依赖、包含等关系。——sigmoid