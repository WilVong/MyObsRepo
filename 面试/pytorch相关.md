# 1 测试技巧
在模型中，我们通常会加上Dropout层和batch normalization层，在模型预测阶段，我们需要将这些层设置到预测模式，model.eval()就是帮我们一键搞定的，如果在预测的时候忘记使用model.eval()，会导致不一致的预测结果。

```
# evaluate model:
model.eval()
with torch.no_grad():
    ...
    out_data = model(data)
    ...
```
在训练之前，我们也要记得将这些特殊的层设置到训练模式：
```
model.train()
```
## 测试时的dropout
Dropout，简单的说，就是我们在前向传播的时候，让某个神经元的激活值以一定的概率p停止工作，这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征。

而在测试时，应该用整个训练好的模型，因此不需要dropout。我们不会对神经元进行随机置0，这就导致预测值和训练值的大小是不一样的。因此，有两个解决办法：
1）在训练中，dropout后，对输出值进行rescale，就是每个神经元的输出值乘以1/(1-p)
2）在测试中，对每个神经元的输出乘以p
这样，使得在训练时和测试时每一层输入有大致相同的期望。
## 测试时的BN
BN，batch normalization，是对数据的规范化，使每层的数据输入都保持在相近的范围内。
BN和核心计算公式：

![](https://pic4.zhimg.com/80/v2-47878a34272f85692afc3acd832da1ab_1440w.webp)

其实是一个均值 μ、方差 σ 的标准分布。
在训练时，由于是一个batch一个batch的给模型投喂数据，模型只能计算当前batch的均值和方差，当所有的batch都投喂完成，模型对每个batch上的均值和方差做指数平均，来得到整个样本上的均值和方差的近似值。
在预测时，一般不必要去计算的均值和方差，比如测试仅对单样本输入进行测试时，这时去计算单样本输入的均值和方差是完全没有意义的。因此会直接拿训练过程中对整个样本空间估算的均值和方差直接来用。