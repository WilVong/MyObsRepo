1.训练大模型的内容，比如模型参数大小，训练一些细节

2.大模型训练的细节之类的，模型端，框架端

3.transformer，训练，分布式，如何处理训练一些问题比如loss spike

4.框架为主的，一面问了很多框架内容，各种模型切分方式

5.flash-attention

6.数据组：大模型数据处理

7.框架端的内容，分布式训练的切割和device之间交流

8.不同device之间communication怎么做，底层communication算法有啥，我答案里有ring-reduce，然后再深入问了reduce底层如何实现

9.做RLHF，强化学习，微调的

10.多头注意力，coding轮，概念轮都考。复习的点包括：时间/空间复杂度，优化（kv-cache，MQA，GQA），手写多头代码。各种Norm，这个频率也不低，不过比较标准的内容，没有啥特意要说的，有的考手写，有的考概念和理解（为什么管用）【S】

11.框架相关内容，各种并行方式，优缺点。DeepSpeed，Megatron可以看看源代码，Flash-Attention等内容。这个点也经常考代码题【S】

12.BERT，GPT等比较主流大模型，一些细节，比如位置编码，训练loss，激活，架构些许不同这种。自回归重点。【S】

13大模型训练，这个可能主要是工作经验相关，经常问比如训练loss炸掉了，如何解决，一些技巧之类的。面试时有些面试官会问一些很细节的东西，感觉是在确认确实上手跑过基座训练不是吹水。【A】

14.数据预处理，BPE，tokenization，mask相关概念和对模型/训练影响，数据配比（有paper）。【A】

15.evaluation，如何评估大模型，安全性，有效性，公开数据，个别考过手写eval框架（多选，生成）。【B】