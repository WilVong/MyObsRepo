# 一  [我的大模型岗位面试总结：共24家，9个offer](https://zhuanlan.zhihu.com/p/662549672) 
1.训练大模型的内容，比如模型参数大小，训练一些细节

2.大模型训练的细节之类的，模型端，框架端

3.transformer，训练，分布式，如何处理训练一些问题比如loss spike

4.框架为主的，一面问了很多框架内容，各种模型切分方式

5.flash-attention

6.数据组：大模型数据处理

7.框架端的内容，分布式训练的切割和device之间交流

8.不同device之间communication怎么做，底层communication算法有啥，我答案里有ring-reduce，然后再深入问了reduce底层如何实现

9.做RLHF，强化学习，微调的

10.多头注意力，coding轮，概念轮都考。复习的点包括：时间/空间复杂度，优化（kv-cache，MQA，GQA），手写多头代码。各种Norm，这个频率也不低，不过比较标准的内容，没有啥特意要说的，有的考手写，有的考概念和理解（为什么管用）【S】

11.框架相关内容，各种并行方式，优缺点。DeepSpeed，Megatron可以看看源代码，Flash-Attention等内容。这个点也经常考代码题【S】

12.BERT，GPT等比较主流大模型，一些细节，比如位置编码，训练loss，激活，架构些许不同这种。自回归重点。【S】

13大模型训练，这个可能主要是工作经验相关，经常问比如训练loss炸掉了，如何解决，一些技巧之类的。面试时有些面试官会问一些很细节的东西，感觉是在确认确实上手跑过基座训练不是吹水。【A】

14.数据预处理，BPE，tokenization，mask相关概念和对模型/训练影响，数据配比（有paper）。【A】

15.evaluation，如何评估大模型，安全性，有效性，公开数据，个别考过手写eval框架（多选，生成）。【B】

# 二  [大模型强化学习面经](https://zhuanlan.zhihu.com/p/659551066)

- PPO算法中使用GAE的好处以及参数 γ\gamma 和 λ\lambda 的作用是什么
- PPO算法和DQN算法的区别是什么
- 有哪些PPO算法的调参经验
- 在线强化学习和离线强化学习在技术和应用场景上有什么区别
- 强化学习和大模型之间的关联是什么
- 如何评估大模型中数据集的质量
- 目前国内一般选择基于哪些基座模型继续训练
- 国内做大模型的主要工作是哪几个部分
- 除了数据之外，还有哪些方向的工作可以进一步优化大模型的效果
- 大语言模型是怎么输出的，观察过输出的概率值吗
- 关于微调的方法有哪些
- 如果让你训练一个模型，基座，数据，finetune的方法怎么选
- 怎么解决大语言模型的幻觉问题，RLHF可以吗
- 是否看好国内做基座模型工作的前景，为什么
- 为什么模型越大，貌似更多地具备AGI的能力？这背后的逻辑是什么
- 介绍下对transformer的了解，网络结构相比于lstm有什么不同
- transformer里用到的正则化方法有哪些
- chatgpt训练过程中，奖励模型有更新吗
- chatgpt强化学习训练阶段还有什么改进的空间和思路吗
- 直接用训练reward model的数据精调模型，而不用强化学习，是否可行？为什么
- 了解bert和gpt网络结构的细节及其差异吗
- 假如reward model不太准，怎么办
- 有做过大模型训练的实践吗，有哪些收获或者感悟

# 三   [应聘大模型（LLMs）算法工程师，有哪些最频繁被问到的面试题？（一）](https://zhuanlan.zhihu.com/p/659970537)
基础面
- 目前 主流的开源模型体系 有哪些？
- prefix Decoder 和 causal Decoder 和 Encoder-Decoder 区别是什么？
- 大模型LLM的 训练目标 是什么？
- 涌现能力是啥原因？
- 为何现在的大模型大部分是Decoder only结构？
- 简单 介绍一下 大模型【LLMs】？
- 大模型【LLMs】后面跟的 175B、60B、540B等 指什么？
- 大模型【LLMs】具有什么优点？
- 大模型【LLMs】具有什么缺点？

进阶面
- LLMs 复读机问题

1. 什么是 LLMs 复读机问题？
2. 为什么会出现 LLMs 复读机问题？
3. 如何缓解 LLMs 复读机问题？

- llama 系列问题

1. llama 输入句子长度理论上可以无限长吗？

- 什么情况用Bert模型，什么情况用LLaMA、ChatGLM类大模型，咋选？
- 各个专业领域是否需要各自的大模型来服务？
- 如何让大模型处理更长的文本


微调面
- 如果想要在某个模型基础上做全参数微调，究竟需要多少显存？
- 为什么SFT之后感觉LLM傻了?
- SFT 指令微调数据 如何构建?
- 领域模型Continue PreTrain 数据选取？
- 领域数据训练后，通用能力往往会有所下降，如何缓解模型遗忘通用能力？
- 领域模型Continue PreTrain ，如何 让模型在预训练过程中就学习到更多的知识？
- 进行SFT操作的时候，基座模型选用Chat还是Base?
- 领域模型微调 指令&数据输入格式 要求？
- 领域模型微调 领域评测集 构建？
- 领域模型词表扩增是不是有必要的？
- 如何训练自己的大模型？
- 训练中文大模型有啥经验？
- 指令微调的好处？
- 预训练和微调哪个阶段注入知识的？
- 想让模型学习某个领域或行业的知识，是应该预训练还是应该微调？
- 多轮对话任务如何微调模型？
- 微调后的模型出现能力劣化，灾难性遗忘是怎么回事？
- 微调模型需要多大显存？
- 大模型LLM进行SFT操作的时候在学习什么？
- 预训练和SFT操作有什么不同
- 样本量规模增大，训练出现OOM错
- 大模型LLM进行SFT 如何对样本进行优化？
- 模型参数迭代实验
- 微调大模型的一些建议

训练面
- 分布式训练框架选择？
- LLMs 训练时 有哪些有用的建议？
- 模型大小如何选择？
- 加速卡如何选择？

# 四  [应聘大模型（LLMs）算法工程师（二）——有哪些基于LLM+向量库的文档对话的面试题最频繁被问到？](https://zhuanlan.zhihu.com/p/659971288)

# 五  [应聘大模型（LLMs）算法工程师（三）——有哪些参数高效微调(PEFT) 面试题最频繁被问到？](https://zhuanlan.zhihu.com/p/659972114)

# 六  [应聘大模型（LLMs）算法工程师（四）——有哪些分布式训练面试题最频繁被问到？](https://zhuanlan.zhihu.com/p/659972521)

# 七 [算法工程师面试汇总](https://www.zhihu.com/column/c_1317403986237448192)
## ## [大模型八股答案（一）——基础知识](https://zhuanlan.zhihu.com/p/643829565)

## ## [大模型面试八股](https://zhuanlan.zhihu.com/p/643560888)


